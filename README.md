# Review.find – корпус рецензий с сайта Кинопоиск
## Команда проекта
Ахсахалян Ольга *osakhsa*, Шаврина Анастасия *shavrinaanastasia*, Шрейбер Анна *tresjuess*, Якубсон Борис *jeraidho*

## Как запустить

- Скопируйте данные корпуса (*metadata.json, tokendata.json, lemma_index.json* etc.) в папку *dataset/* – все наши собранные данные хранятся [здесь](https://drive.google.com/file/d/1UPPI4aAALUcYb3n7L0M6NiX6bRU4dw8j/view?usp=drive_link) в архиве
- Запустите *\_\_init\_\_.py* с веб-приложением Flask

## Структура репозитория
### Ветки

**data-mining**: изменение скриптов, связанных с предобработкой и хранением данных, поиском и индексацией
**flask_application**: изменение скриптов, связанных с работой веб-приложения на Flask, изменение html, css

### Файлы

**dataset/**: папка с файлами корпуса и скриптами для работы с ними
- datalib.py – основной скрипт для работы с данными корпуса и поиска по ним, содержит классы для этого, такие как Review, ReviewCrawler, Processor и SentenceFinder
- reviews.json – json-файл с необработанными собранными рецензиями
- metadata.json – json-файл с обработанными рецензиями, имеют id рецензии, метатеги (sentiment, film_name), а также полный текст и список разделенных предложений
- tokendata.json – json-файл с обработанными токенами из рецензий с морфологической и синтаксической разметкой каждого вхождения токена в рецензиях
- lemma_index.json – json-файл с индексом по леммам содержит леммы в ключах и список токенов с соответствующей леммой внутри списка
- data-requirements.txt – необходимые библиотеки для работы с данными

**static/**: папка с css-файлами для отображения страниц сайте

**templates/**: папка с html-файлами сайта

\_\_init\_\_.py: основной скрипт Flask с веб-приложением 

## Сбор корпуса и предобработка
Корпус был собран из 600 рецензий Кинопоиска за последний месяц с помощью класса ReviewCrawler. Далее с помощью библиотеки Stanza текст каждой рецензии был обработан – текст рецензии, предложения, а также метаданные про рецензию, включая названия фильма и тональность рецензии, были сохранены в *metadata.json*, а информация о вхождении токенов и информации о них – в *tokendata.json*. Морфологическая разметка частей речи – UD. 

Для оптимизации поиска были реализованы методы создания индексов разметка – список токенов с такой разметкой или "внутренних" индексов разметка – список значений у токенов с такой разметкой. В поиске используется *lemma_index.json* содержащий в ключах леммы, а в значениях списки токенов с соответствующей леммой. 
Сама функция поиска реализованная классом SentenceFinder умеет использовать все перечисленные файлы с данными по запросу, а также искать по метатегам, как тональность рецензии. Метод *render_query()* разделяет пользовательский запрос на множество подзадач поиска и ищет по файлам и индексам соответствующие вхождения. 

Использование хэш-таблиц для всех данных и индексов позволяет ускорить обращение к данным и найти соответствующие токены. Наиболее простым поиском является поиск по токену и лемме, так как они представлены в соответствующих индексах, но поиск по разметке также не занимает много времени.